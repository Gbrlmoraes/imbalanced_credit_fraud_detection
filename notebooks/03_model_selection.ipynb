{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48ac32a8",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6da1a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import mlflow\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "ROOT_DIR = os.path.join(os.getcwd(), '..')\n",
    "DATA_DIR = os.path.join(ROOT_DIR, 'data')\n",
    "\n",
    "mlflow.set_tracking_uri(os.getenv('MLFLOW_TRACKING_URI'))\n",
    "mlflow.set_experiment('Imbalanced Credit Card Fraud Detection')\n",
    "mlflow.sklearn.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074ef5fe",
   "metadata": {},
   "source": [
    "## Choosing the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20eed9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_model_results(y_true, y_hat):\n",
    "    \"\"\"Calculate, print, and log metrics and artifacts to MLflow.\"\"\"\n",
    "\n",
    "    recall = recall_score(y_true, y_hat)\n",
    "    f1 = f1_score(y_true, y_hat)\n",
    "    precision = precision_score(y_true, y_hat, zero_division=1)\n",
    "    accuracy = accuracy_score(y_true, y_hat)\n",
    "\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"test_recall\": recall,\n",
    "        \"test_f1_score\": f1,\n",
    "        \"test_precision\": precision,\n",
    "        \"test_accuracy\": accuracy\n",
    "    }\n",
    "    mlflow.log_metrics(metrics_dict)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = confusion_matrix(y_true, y_hat, labels=[0, 1])\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['No Fraud (P)', 'Fraud (P)'],\n",
    "                yticklabels=['No Fraud (T)', 'Fraud (T)'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.plot()\n",
    "\n",
    "    confusion_matrix_path = \"confusion_matrix.png\"\n",
    "    plt.savefig(confusion_matrix_path)\n",
    "    plt.close()\n",
    "\n",
    "    mlflow.log_artifact(confusion_matrix_path, \"plots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a516511",
   "metadata": {},
   "source": [
    "## Establishing a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4fd8d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
    "df_test = pd.read_csv(os.path.join(DATA_DIR, 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a50c067a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/13 23:32:13 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "c:\\git_reps\\imbalanced_credit_fraud_detection\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Precision: 1.0000\n",
      "Accuracy: 0.9983\n",
      "üèÉ View run Baseline Model at: http://localhost:5000/#/experiments/713154386041343957/runs/42c9e90c82434f0dbaf1c0a06644b092\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/713154386041343957\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name='Baseline Model'):\n",
    "\n",
    "    baseline = DummyClassifier(strategy='most_frequent')\n",
    "    baseline.fit(df_train.drop(columns=['Class']), df_train['Class'])\n",
    "\n",
    "    y_hat = baseline.predict(df_test.drop(columns=['Class']))\n",
    "\n",
    "    log_model_results(df_test['Class'], y_hat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imbalanced-credit-fraud-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
